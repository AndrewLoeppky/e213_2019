{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0,
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-objectives\" data-toc-modified-id=\"Learning-objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Learning objectives</a></span></li><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#The-context-module\" data-toc-modified-id=\"The-context-module-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>The context module</a></span></li><li><span><a href=\"#Reading-the-processed-data\" data-toc-modified-id=\"Reading-the-processed-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Reading the processed data</a></span></li><li><span><a href=\"#Metadata-is-data-about-data\" data-toc-modified-id=\"Metadata-is-data-about-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Metadata is data about data</a></span></li><li><span><a href=\"#Read-weather_YVR.csv-into-a-dataframe\" data-toc-modified-id=\"Read-weather_YVR.csv-into-a-dataframe-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Read weather_YVR.csv into a dataframe</a></span></li><li><span><a href=\"#Use-apply-to-tag-the-29,190-days-with-their-season\" data-toc-modified-id=\"Use-apply-to-tag-the-29,190-days-with-their-season-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Use apply to tag the 29,190 days with their season</a></span><ul class=\"toc-item\"><li><span><a href=\"#creating-a-new-column-with-apply\" data-toc-modified-id=\"creating-a-new-column-with-apply-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>creating a new column with apply</a></span></li></ul></li><li><span><a href=\"#Grouping-the-data-by-season\" data-toc-modified-id=\"Grouping-the-data-by-season-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Grouping the data by season</a></span><ul class=\"toc-item\"><li><span><a href=\"#Use-a-dictionary-comprehension-put-the-dataframes-into-a-dictionary\" data-toc-modified-id=\"Use-a-dictionary-comprehension-put-the-dataframes-into-a-dictionary-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Use a dictionary comprehension put the dataframes into a dictionary</a></span></li></ul></li><li><span><a href=\"#Fitting-the-distributions\" data-toc-modified-id=\"Fitting-the-distributions-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Fitting the distributions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Daily-average-temperature\" data-toc-modified-id=\"Daily-average-temperature-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Daily average temperature</a></span></li><li><span><a href=\"#Daily-average-total-precipitation\" data-toc-modified-id=\"Daily-average-total-precipitation-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Daily average total precipitation</a></span></li></ul></li><li><span><a href=\"#Saving-the-fit-parameters\" data-toc-modified-id=\"Saving-the-fit-parameters-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Saving the fit parameters</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Generating random precip and temperature data\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "1. Document your project data by capturing important information\n",
    "   as metadata in a json file\n",
    "\n",
    "1. Use the groupby method for a pandas dataframe to group observations\n",
    "   by season\n",
    "\n",
    "1. Find the probability density function (histogram) of temperature and\n",
    "   precipitation data and determine possible statistical models (normal distribution,\n",
    "   exponential distribution) that best describe the variation in the data\n",
    "\n",
    "1. Find best fit parameters for statistical models that describe the precipitation\n",
    "   and temperature data, assuming that temperature and precipitation are\n",
    "   independent of each other.\n",
    "\n",
    "1. Use those parameters to generate random data that simulate daily precipitation\n",
    "   and temperature at YVR airport\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We have about 30,000 days worth of YVR precipitation and temperature\n",
    "data generated by the 10-pandas1, 10-pandas2, and 10-pandas3 notebooks, these\n",
    "gave you a new csv file: data/processed/weather_YVR.csv.  We will use\n",
    "that data set to estimate statistical distributions that could produce realistic\n",
    "simulated rainfall and temperature inputs to a model.  It makes use of several\n",
    "new python modules/methods:\n",
    "\n",
    "1. The **context** module: We will write a new module called context.py that\n",
    "   will be used to locate folders and libraries associated with a project, such as\n",
    "   `weather_YVR.csv`.\n",
    "1. **The json module**.  This reads and writes files written\n",
    "   in \"javascript object notation\" i.e.\n",
    "   [json](https://en.wikipedia.org/wiki/JSON).  We will use it to\n",
    "   save \"metadata\" or data about our data.\n",
    "\n",
    "1. **pandas.DataFrame.groupby**\n",
    "   We will use groupby to split the dataframe into 4 seasons, each corresponding\n",
    "   to 3 months of the year: winter (month initials djf), spring (mam),\n",
    "   summer (jja), and fall (son).  This is the tip of the iceberg of what\n",
    "   you can do with pandas split/apply/combine functions.  For more examples\n",
    "   see [the Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.08-Aggregation-and-Grouping.ipynb)\n",
    "\n",
    "1. The [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html) module.  As you will see\n",
    "   below, the temperature data is best fit with a a Gaussian (normal) distribution\n",
    "   using the norm.fit:\n",
    "   - [scipy.stats.norm.fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm)\n",
    "\n",
    "   Precipitation, on the other hand, follows an exponential distribution, which\n",
    "   can be fit with:\n",
    "   - [scipy.stats.expon.fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html#scipy.stats.expon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import context\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## The context module\n",
    "\n",
    "As our project grows more complicated, it's good to have a central\n",
    "module that keeps track of important files and sets your scripts\n",
    "up so that they can import functions and classes from you modules.\n",
    "If you were planning to distribute your project using conda, then\n",
    "you would need to write an installation script, which is a fair\n",
    "amount of work.   At this stage, it's easier and more flexible to\n",
    "store that information in a file that travels along with your notebook.\n",
    "By convention, this file is called:\n",
    "[context.py](https://github.com/phaustin/eosc213_students/blob/master/notebooks/pandas/context.py)\n",
    "\n",
    "Clicking on that link shows you the source -- the code is executed when\n",
    "you do `import context` and does the following:\n",
    "\n",
    "1. Defines Path objects that give the location of the raw and processed data folders\n",
    "\n",
    "1. Puts the notebooks/pandas folder on python's list of places to look for\n",
    "   library modules (sys.path).  We will use this when we start extracting\n",
    "   code from notebooks into libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Here is the path to the processed csv file\n",
    "#\n",
    "print(context.processed_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the processed data\n",
    "\n",
    "The next cell uses [\"globbing\"](https://en.wikipedia.org/wiki/Glob_(programming)) to\n",
    "find every csv file in all folders below `data/processed`.  (See\n",
    "[this optional tutorial](https://realpython.com/python-pathlib/) for more information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = context.processed_dir.glob(\"**/*csv\")\n",
    "all_files = list(all_files)\n",
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata is data about data\n",
    "\n",
    "Since we care about this dataset, it's a good idea to save\n",
    "details for future reference.  We can't put this kind of information\n",
    "into a csv file, but there are many file formats that can store\n",
    "this type of descriptive metadata -- one of the most popular is\n",
    "[json](https://en.wikipedia.org/wiki/JSON).  In the next cell we\n",
    "write the data into a nested dictionary called meta_dict, and\n",
    "dump that information into a new json file called metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = dict()\n",
    "\n",
    "file_info = dict()\n",
    "file_info[\"written_by\"] = \"10-pandas3-process-daily-data.ipynb\"\n",
    "file_info[\"contact\"] = \"paustin@eoas.ubc.ca\"\n",
    "file_info[\n",
    "    \"description\"\n",
    "] = \"EC canada YVR data downloaded by 10-pandas2-download-daily-data.ipynb\"\n",
    "\n",
    "meta_data[\"weather_daily_YVR_1938-2017_all.csv\"] = file_info\n",
    "\n",
    "file_info = dict()\n",
    "file_info[\"written_by\"] = \"10-pandas3-process-daily-data.ipynb\"\n",
    "file_info[\"contact\"] = \"paustin@eoas.ubc.ca\"\n",
    "file_info[\n",
    "    \"description\"\n",
    "] = \"Reduced YVR data subsetted by 10-pandas3-process-daily-data.ipynb\"\n",
    "\n",
    "meta_data[\"weather_YVR.csv\"] = file_info\n",
    "\n",
    "history_file = context.processed_dir / \"history_metadata.json\"\n",
    "with open(history_file, \"w\") as f:\n",
    "    json.dump(meta_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a minute and look at history_metadata.json with jupyter to see how the metadata is written out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read weather_YVR.csv into a dataframe\n",
    "\n",
    "Here's the dataframe produced by 10-pandas3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvr_df = pd.read_csv(all_files[1])\n",
    "yvr_df.fillna(0.0, inplace=True)\n",
    "print(f\"there are {len(yvr_df)} days in the dataframe\")\n",
    "yvr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use apply to tag the 29,190 days with their season\n",
    "\n",
    "We know that the seasons are quite different, and if we are interested in\n",
    "generating daily data we have to take that into account.  In the next cell\n",
    "we set up a lookup table (dictionary) called season_table that maps the\n",
    "month number to one of four seasons.  With this table we can write\n",
    "a function called find_season that takes a row of the dataframe and\n",
    "returns the season for that row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_table = dict()\n",
    "for i in range(12):\n",
    "    m = i + 1\n",
    "    if m in [12, 1, 2]:\n",
    "        # winter\n",
    "        season_table[m] = \"djf\"\n",
    "    elif m in [3, 4, 5]:\n",
    "        # spring\n",
    "        season_table[m] = \"mam\"\n",
    "    elif m in [6, 7, 8]:\n",
    "        # summer\n",
    "        season_table[m] = \"jja\"\n",
    "    else:\n",
    "        # fall\n",
    "        season_table[m] = \"son\"\n",
    "\n",
    "\n",
    "def find_season(row, season_table):\n",
    "    month = row[\"Month\"]\n",
    "    return season_table[month]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating a new column with apply\n",
    "\n",
    "We apply the find_season function to every row of the dataframe in the\n",
    "cell below.  `axis=1` tells apply that we want to produce a new column\n",
    "(axis 1), not a new row (axis 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = yvr_df.apply(find_season, args=(season_table,), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add that column to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvr_df[\"season\"] = season\n",
    "yvr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping the data by season\n",
    "\n",
    "The next cell uses the groupby method to sort all of the\n",
    "rows into 4 seasons.  The resulting group object (`seasons`) has\n",
    "4 dataframes inside it, keyed by the season marker djf, mam, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = yvr_df.groupby(\"season\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a dictionary comprehension put the dataframes into a dictionary\n",
    "\n",
    "In the 10-pandas3 notebook we used a dictionary comprehension.  We'll use\n",
    "one again below -- it will have 4 keys, one for each season, with each\n",
    "key pointing to the seasonal dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dict = {key: value for key, value in seasons}\n",
    "season_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the fall dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_dict[\"son\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the distributions\n",
    "\n",
    "### Daily average temperature\n",
    "\n",
    "The next cell shows histograms temperature for each of the seasons.  We use\n",
    "[scipy.stats.norm.fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm) to\n",
    "find the mean and standard deviation (called the `loc` and `scale` here) of the data\n",
    "and then shows that fitted distribution as a red line.  Specifically, for temperatures x the red\n",
    "line is a plot of:\n",
    "\n",
    "\\begin{align*}\n",
    "f(y) &= \\frac{\\exp(-y^2/2)}{\\sqrt{2\\pi}} \\\\\n",
    "y &= (x - loc) / scale\n",
    "\\end{align*}\n",
    "\n",
    "The four plots show that a normal distribution give as pretty good representation of each of the seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_list = [\"djf\", \"mam\", \"jja\", \"son\"]\n",
    "df_list = [season_dict[key] for key in key_list]\n",
    "fig, ax_array = plt.subplots(2, 2, figsize=(8, 8))\n",
    "ax_list = ax_array.flatten()\n",
    "var = \"T_mean (C)\"\n",
    "temp_params = dict()\n",
    "for index, key in enumerate(key_list):\n",
    "    the_ax = ax_list[index]\n",
    "    the_df = df_list[index]\n",
    "    the_temps = the_df[var]\n",
    "    mu, sigma = st.norm.fit(the_temps)\n",
    "    temp_params[key] = (mu, sigma)\n",
    "    vals, bins, patches = the_ax.hist(var, bins=20, data=the_df, density=True)\n",
    "    bin_centers = (bins[1:] + bins[0:-1]) / 2.0\n",
    "    the_ax.plot(bin_centers, st.norm.pdf(bin_centers, mu, sigma), \"r-\")\n",
    "    the_ax.grid(True)\n",
    "    the_ax.set(title=key)\n",
    "    if index > 1:\n",
    "        the_ax.set(xlabel=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daily average total precipitation\n",
    "\n",
    "Precipitation data is a different story.  Because negative precipitation\n",
    "is impossible, there is no way a normal distribution is going to work\n",
    "to represent the variablity.  Instead we use\n",
    "[scipy.stats.expon.fit](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html#scipy.stats.expon) to fit an exponential distribution.\n",
    "\n",
    "\\begin{align*}\n",
    "f(y) &= \\exp(-y)\\\\\n",
    "y &= (x - loc) / scale\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "where `loc` is the minimum of the data and `scale` is the distance\n",
    "between the minimum and the mean.\n",
    "\n",
    "The fits are not quite as good -- but do capture the one-sided nature\n",
    "of the variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_array = plt.subplots(2, 2, figsize=(8, 8))\n",
    "ax_list = ax_array.flatten()\n",
    "var = \"Total Precip (mm)\"\n",
    "precip_params = dict()\n",
    "for index, key in enumerate(key_list):\n",
    "    the_ax = ax_list[index]\n",
    "    the_df = df_list[index]\n",
    "    the_precip = the_df[var]\n",
    "    loc, scale = st.expon.fit(the_precip)\n",
    "    precip_params[key] = (loc, scale)\n",
    "    vals, bins, patches = the_ax.hist(var, bins=20, data=the_df, density=True)\n",
    "    bin_centers = (bins[1:] + bins[0:-1]) / 2.0\n",
    "    the_ax.plot(bin_centers, st.expon.pdf(bin_centers, loc, scale), \"r-\")\n",
    "    the_ax.grid(True)\n",
    "    the_ax.set(title=key)\n",
    "    if index > 1:\n",
    "        the_ax.set(xlabel=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the fit parameters\n",
    "\n",
    "We have two new dictionaries: `temp_params` and `precip_params` that\n",
    "we should save for the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "data_dict[\n",
    "    \"metadata\"\n",
    "] = \"\"\"\n",
    "          loc,scale tuples for daily average temperature (deg C)\n",
    "          and precipitation (mm) produced by 11-pandas4 for YVR\n",
    "          \"\"\"\n",
    "data_dict[\"temp\"] = temp_params\n",
    "data_dict[\"precip\"] = precip_params\n",
    "fit_file = context.processed_dir / \"fit_metadata.json\"\n",
    "with open(fit_file, \"w\") as f:\n",
    "    json.dump(data_dict, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "all",
   "notebook_metadata_filter": "all,-language_info",
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "1.0.3"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
